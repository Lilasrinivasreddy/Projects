# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import ttest_ind, mannwhitneyu
from sklearn.ensemble import IsolationForest
from sklearn.cluster import DBSCAN
from sklearn.preprocessing import StandardScaler
import statsmodels.api as sm
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from statsmodels.tsa.seasonal import seasonal_decompose

# Load dataset
df = pd.read_csv("your_data.csv")

# Convert dates to datetime format
df['RPT_DT'] = pd.to_datetime(df['RPT_DT'])
df['ACTIVITY_DT'] = pd.to_datetime(df['ACTIVITY_DT'])

# Drop any duplicates
df = df.drop_duplicates()

# Handling missing values (if any)
df.fillna(0, inplace=True)

# Display dataset overview
print("\nDataset Info:")
print(df.info())

# Display first few rows
print("\nFirst 5 Rows of Data:")
print(df.head())

# Descriptive statistics
print("\nDescriptive Statistics:")
summary_stats = df[['SALES', 'GROSS_ADDS']].describe()
print(summary_stats)

# Correlation Analysis
correlation_matrix = df[['SALES', 'GROSS_ADDS']].corr()
plt.figure(figsize=(6, 4))
sns.heatmap(correlation_matrix, annot=True, cmap="coolwarm", fmt=".2f")
plt.title("Correlation between SALES & GROSS_ADDS")
plt.show()

# Moving Averages for Trend Analysis
df['MA_SALES'] = df['SALES'].rolling(window=7).mean()
df['MA_GROSS_ADDS'] = df['GROSS_ADDS'].rolling(window=7).mean()

# SALES & GROSS_ADDS Trend Over Time
plt.figure(figsize=(14, 6))
plt.plot(df['ACTIVITY_DT'], df['SALES'], label="Actual SALES", alpha=0.5, color='blue')
plt.plot(df['ACTIVITY_DT'], df['MA_SALES'], label="7-Day Moving Avg (SALES)", color="red")
plt.plot(df['ACTIVITY_DT'], df['GROSS_ADDS'], label="Actual GROSS_ADDS", alpha=0.5, color='green')
plt.plot(df['ACTIVITY_DT'], df['MA_GROSS_ADDS'], label="7-Day Moving Avg (GROSS_ADDS)", color="orange")
plt.title("SALES & GROSS_ADDS Trend Over Time")
plt.xlabel("Date")
plt.ylabel("Value")
plt.legend()
plt.grid()
plt.show()

# Sales Distribution by Channel
plt.figure(figsize=(10, 5))
sns.boxplot(data=df, x='Channel', y='SALES', palette="coolwarm")
plt.title("Sales Distribution by Channel")
plt.grid()
plt.show()

# Gross Adds Distribution by Channel
plt.figure(figsize=(10, 5))
sns.boxplot(data=df, x='Channel', y='GROSS_ADDS', palette="coolwarm")
plt.title("Gross Adds Distribution by Channel")
plt.grid()
plt.show()

# Anomaly Detection using Isolation Forest for SALES & GROSS_ADDS
iso_forest = IsolationForest(contamination=0.05, random_state=42)
df['IF_OUTLIER'] = iso_forest.fit_predict(df[['SALES', 'GROSS_ADDS']])
df['IF_OUTLIER_LABEL'] = df['IF_OUTLIER'].apply(lambda x: "Anomaly" if x == -1 else "Normal")

plt.figure(figsize=(14, 6))
sns.scatterplot(data=df, x="ACTIVITY_DT", y="SALES", hue="IF_OUTLIER_LABEL", palette={"Anomaly": "red", "Normal": "blue"})
plt.title("SALES Anomalies Detected by Isolation Forest")
plt.xlabel("Date")
plt.ylabel("Sales")
plt.grid()
plt.show()

# DBSCAN Clustering for Outlier Detection
scaler = StandardScaler()
df_scaled = scaler.fit_transform(df[['SALES', 'GROSS_ADDS']])
dbscan = DBSCAN(eps=1.5, min_samples=5)
df['DBSCAN_OUTLIER'] = dbscan.fit_predict(df_scaled)

plt.figure(figsize=(14, 6))
sns.scatterplot(data=df, x="ACTIVITY_DT", y="SALES", hue=df['DBSCAN_OUTLIER'], palette="coolwarm")
plt.title("DBSCAN Outlier Detection for SALES")
plt.xlabel("Date")
plt.ylabel("Sales")
plt.grid()
plt.show()

# Time-Series Decomposition for SALES
df_sorted = df.sort_values(by="ACTIVITY_DT")
df_sorted.set_index("ACTIVITY_DT", inplace=True)
result = seasonal_decompose(df_sorted['SALES'], model='additive', period=7)
result.plot()
plt.show()

# Autocorrelation Analysis
plt.figure(figsize=(12, 6))
plot_acf(df_sorted['SALES'], lags=30)
plt.title("Autocorrelation Function (ACF) for SALES")
plt.show()

plt.figure(figsize=(12, 6))
plot_pacf(df_sorted['SALES'], lags=30)
plt.title("Partial Autocorrelation Function (PACF) for SALES")
plt.show()

# Hypothesis Testing for SALES between Digital & Stores
digital_sales = df[df['Channel'] == 'Digital']['SALES']
stores_sales = df[df['Channel'] == 'Stores']['SALES']
t_stat, p_value = ttest_ind(digital_sales, stores_sales)

print("\nT-Test for SALES between Digital & Stores:")
print(f"T-Statistic: {t_stat:.4f}, P-Value: {p_value:.4f}")

mwu_stat, mwu_p = mannwhitneyu(digital_sales, stores_sales)

print("\nMann-Whitney U Test Results:")
print(f"U-Statistic: {mwu_stat:.4f}, P-Value: {mwu_p:.4f}")

# Save processed data
df.to_csv("processed_sales_gross_adds_analysis.csv", index=False)
print("Processed data saved successfully!")
