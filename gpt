
# ====================================================================================
# CONVERSATIONAL FEATURE: BigQuery Table
# ====================================================================================

class BigQueryTransactionManager:
    """
    Session managing for conversational AI using existing BigQuery table
    """
    
    def __init__(self):
        self.in_memory_sessions = {}  # Fallback storage for conversation context
        self.bigquery_client = None
        
        try:
            from google.cloud import bigquery
            self.bigquery_client = bigquery.Client()
            print(f"Connected to BigQuery for logging")
        except ImportError:
            print(f"BigQuery client not available")
        except Exception as e:
            print(f"Failed to connect to BigQuery: {e}. Using in-memory storage only.")
    
    def create_session(self, user_id: str, use_case: str = "aider", 
                      slack_channel_id: str = None, slack_thread_ts: str = None,
                      metadata: dict = None) -> str:
        """Create a new conversation session and initialize transaction"""
        session_id = str(uuid.uuid4())
        transaction_id = str(uuid.uuid4())
        
        # Store session context in memory for quick access during conversation
        session_data = {
            "session_id": session_id,
            "transaction_id": transaction_id,
            "user_id": user_id,
            "slack_channel_id": slack_channel_id,
            "slack_thread_ts": slack_thread_ts,
            "use_case": use_case,
            "created_at": datetime.utcnow(),
            "conversation_history": [],
            "metadata": metadata or {},
            "is_active": True
        }
        
        # Store in memory for conversation context
        self.in_memory_sessions[session_id] = session_data
        
        # Log session creation in BigQuery transaction table
        if self.bigquery_client:
            try:
                self._log_transaction_event(
                    transaction_id=transaction_id,
                    session_id=session_id,
                    slackid=slack_channel_id,
                    mail_id=user_id,
                    platform="aider_conversational",
                    start_timestamp=datetime.utcnow(),
                    transaction_type="session_created",
                    form_input=json.dumps(metadata or {})
                )
                print(f"Session {session_id} logged to BigQuery")
            except Exception as e:
                print(f"BigQuery logging failed: {e}. Session created in memory only.")

        return session_id
    
    def get_session(self, session_id: str) -> Optional[Dict]:
        """Retrieve session from in-memory storage (sessions are lightweight for conversation context)"""
        return self.in_memory_sessions.get(session_id)
    
    def get_session_history_from_bigquery(self, session_id: str, limit: int = 10) -> List[Dict]:
        """Retrieve conversation history from BigQuery transaction table"""
        if not self.bigquery_client:
            return []
            
        try:
            query = f"""
            SELECT 
                transaction_id,
                start_timestamp,
                query,
                response_llmgen,
                standalone_query,
                user_reaction,
                feedback_text
            FROM `{DPF_CONVERSATION_CONFIG.get('bigquery_table', 'your_project.your_dataset.transactions')}`
            WHERE session_id = @session_id 
              AND transaction_type = 'conversational_query'
              AND query IS NOT NULL
            ORDER BY start_timestamp ASC
            LIMIT @limit
            """
            
            job_config = self.bigquery_client.QueryJobConfig(
                query_parameters=[
                    self.bigquery_client.ScalarQueryParameter("session_id", "STRING", session_id),
                    self.bigquery_client.ScalarQueryParameter("limit", "INT64", limit)
                ]
            )
            
            results = self.bigquery_client.query(query, job_config=job_config)
            
            history = []
            for row in results:
                history.append({
                    "transaction_id": row.transaction_id,
                    "timestamp": row.start_timestamp.isoformat() if row.start_timestamp else None,
                    "question": row.query,
                    "answer": row.response_llmgen,
                    "standalone_query": row.standalone_query,
                    "user_reaction": row.user_reaction,
                    "feedback_text": row.feedback_text
                })
            
            return history
        except Exception as e:
            print(f"Failed to retrieve session history from BigQuery: {e}")
            return []
    
    def log_conversational_transaction(self, session_id: str, original_query: str, 
                                     contextualized_query: str, response: str,
                                     retrieved_docs: list = None, api_response_time: float = None):
        """Log complete conversational transaction to BigQuery (Step 6 of architecture)"""
        session = self.get_session(session_id)
        if not session:
            raise ValueError(f"Session {session_id} not found")
            
        transaction_id = str(uuid.uuid4())
        current_time = datetime.utcnow()
        
        # Update in-memory session history for quick access
        new_entry = {
            "timestamp": current_time.isoformat(),
            "question": original_query,
            "answer": response,
            "standalone_query": contextualized_query,
            "retrieved_docs": retrieved_docs[:3] if retrieved_docs else []
        }
        
        history = session.get("conversation_history", [])
        history.append(new_entry)
        
        # Keep only recent history in memory
        max_turns = DPF_CONVERSATION_CONFIG["max_history_turns"]
        if len(history) > max_turns:
            history = history[-max_turns:]
            
        self.in_memory_sessions[session_id]["conversation_history"] = history
        
        # Log full transaction to BigQuery
        if self.bigquery_client:
            try:
                response_doc = []
                if retrieved_docs:
                    for doc in retrieved_docs[:3]:
                        if isinstance(doc, dict):
                            response_doc.append({
                                "score": doc.get("cross_score", 0),
                                "content": doc.get("text_content", "")[:500]  # Truncate for storage
                            })
                
                self._log_transaction_event(
                    transaction_id=transaction_id,
                    session_id=session_id,
                    slackid=session.get("slack_channel_id"),
                    mail_id=session.get("user_id"),
                    platform="aider_conversational",
                    start_timestamp=current_time,
                    query=original_query,
                    response_llmgen=response,
                    response_doc=json.dumps(response_doc),
                    transaction_type="conversational_query",
                    api_response_time_in_ms=int(api_response_time * 1000) if api_response_time else None,
                    standalone_query=contextualized_query,
                    end_timestamp=current_time
                )
                print(f"Logged conversational transaction {transaction_id} to BigQuery")
            except Exception as e:
                print(f"BigQuery transaction logging failed: {e}")
    
    def close_session(self, session_id: str):
        """Close/deactivate a session"""
        if session_id in self.in_memory_sessions:
            session = self.in_memory_sessions[session_id]
            session["is_active"] = False
            
            # Log session closure to BigQuery
            if self.bigquery_client:
                try:
                    transaction_id = str(uuid.uuid4())
                    self._log_transaction_event(
                        transaction_id=transaction_id,
                        session_id=session_id,
                        slackid=session.get("slack_channel_id"),
                        mail_id=session.get("user_id"),
                        platform="aider_conversational",
                        start_timestamp=datetime.utcnow(),
                        transaction_type="session_closed",
                        end_timestamp=datetime.utcnow()
                    )
                    print(f"Session {session_id} closed and logged to BigQuery")
                except Exception as e:
                    print(f"Failed to log session closure: {e}")
    
    def _log_transaction_event(self, transaction_id: str, session_id: str = None, slackid: str = None,
                              mail_id: str = None, platform: str = None, start_timestamp: datetime = None,
                              query: str = None, response_llmgen: str = None, response_doc: str = None,
                              transaction_type: str = None, user_reaction: str = None, 
                              feedback_text: str = None, refine_index: str = None,
                              api_response_time_in_ms: int = None, db_insertion_time_in_ms: int = None,
                              create_ticket_time_in_ms: int = None, update_ticket_time_in_ms: int = None,
                              form_input: str = None, end_timestamp: datetime = None, 
                              tkt_num: str = None, standalone_query: str = None):
        """Helper method to log events to BigQuery transaction table"""
        if not self.bigquery_client:
            return
            
        try:
            table_id = DPF_CONVERSATION_CONFIG.get('bigquery_table', 'your_project.your_dataset.transactions')
            
            rows_to_insert = [{
                "transaction_id": transaction_id,
                "slackid": slackid,
                "mail_id": mail_id,
                "platform": platform or "aider_conversational",
                "start_timestamp": start_timestamp,
                "query": query,
                "response_llmgen": response_llmgen,
                "response_doc": response_doc,
                "transaction_type": transaction_type,
                "user_reaction": user_reaction,
                "feedback_text": feedback_text,
                "refine_index": refine_index,
                "api_response_time_in_ms": api_response_time_in_ms,
                "db_insertion_time_in_ms": db_insertion_time_in_ms,
                "create_ticket_time_in_ms": create_ticket_time_in_ms,
                "update_ticket_time_in_ms": update_ticket_time_in_ms,
                "form_input": form_input,
                "end_timestamp": end_timestamp,
                "tkt_num": tkt_num,
                "standalone_query": standalone_query,
                "session_id": session_id
            }]
            
            table = self.bigquery_client.get_table(table_id)
            errors = self.bigquery_client.insert_rows_json(table, rows_to_insert)
            
            if errors:
                print(f"BigQuery insert errors: {errors}")
            
        except Exception as e:
            print(f"BigQuery logging error: {e}")

# Initialize global transaction manager
transaction_manager = BigQueryTransactionManager()

# Helper functions
def detect_followup_question(query: str) -> bool:
    """
    Detect if the current query is a follow-up question
    """
    if not DPF_CONVERSATION_CONFIG["enable_followup_detection"]:
        return False
    
    query_lower = query.lower().strip()
    followup_keywords = DPF_CONVERSATION_CONFIG["followup_keywords"] 
    
    # Check for follow-up indicators
    for keyword in followup_keywords:
        if keyword in query_lower:
            return True
    
    # Check if query is very short (likely referring to previous context)
    if len(query_lower.split()) <= 3:
        return True
        
    return False

async def reformulate_query_with_history(current_query: str, conversation_history: list, use_case: str) -> str:
    """
    Contextualize query using conversation history and LLM
    This implements the "Contextualize with LLM + History" step
    """
    if not conversation_history or not DPF_CONVERSATION_CONFIG["enable_query_reformulation"]:
        return current_query
    
    # Build conversation context (recent history only)
    context_parts = []
    recent_history = conversation_history[-3:]  # Last 3 Q&A pairs
    
    for i, entry in enumerate(recent_history):
        context_parts.append(f"Q{i+1}: {entry['question']}")
        context_parts.append(f"A{i+1}: {entry['answer'][:200]}...")  # Truncate long answers
    
    conversation_context = "\n".join(context_parts)
    
    # Create reformulation prompt
    reformulation_prompt = f"""
Based on the following conversation history, please reformulate the current question to be standalone and clear.
Conversation History:
{conversation_context}
Current Question: {current_query}
Please provide a clear, standalone version of the current question that incorporates necessary context from the conversation history. Return only the reformulated question, no explanations.
"""  
    # Use LLM to reformulate query
    try:
        headers = {
            'Content-Type': 'application/json',
            'X-apikey': DPF_API_KEY
        }
        
        payload = {
            "useCase": "AIDER",
            "contextId": DPF_CONVERSATION_CONFIG["reformulation_context_id"],
            "preSeed_injection_map": {
                "{QUESTION}": reformulation_prompt
            },
            "parameters": {
                "maxOutputTokens": 500 
            }
        }
        
        response = requests.post(
            DPF_ENDPOINTS["llm_endpoint"],
            headers=headers,
            data=json.dumps(payload)
        )
        response.raise_for_status()
        result = response.json()
        
        # Extract reformulated query
        reformulated = None
        if isinstance(result, dict) and 'prediction' in result:
            reformulated = result['prediction'].strip()
        elif isinstance(result, str):
            reformulated = result.strip()
        
        if reformulated and len(reformulated) > 10:  # Valid reformulation
            print(f"Query reformulated: '{current_query}' → '{reformulated}'")
            return reformulated
        else:
            print(f"Reformulation failed, using original query")
            return current_query
            
    except Exception as e:
        print(f"Query reformulation failed: {e}. Using original query.")
        return current_query

def build_conversational_context(conversation_history: list, current_query: str) -> str:
    """
    Step 5 Helper: Build conversational context for LLM response generation
    """
    if not conversation_history:
        return ""
    
    # Get recent history for context
    recent_history = conversation_history[-2:]  # Last 2 Q&A pairs
    context_parts = ["Previous conversation context:"]
    
    for i, entry in enumerate(recent_history):
        context_parts.append(f"Previous Q: {entry['question']}")
        context_parts.append(f"Previous A: {entry['answer'][:300]}...")  # Truncated
    
    context_parts.append(f"Current Question: {current_query}")
    
    return "\n".join(context_parts)

# Endpoint
@app.post("/vegas/apps/aider-retriever/dpf/conversational/api")
async def conversational_search_endpoint(request: ConversationalQuery):
    """
    Conversational feature
    """
    try:
        start_time = time.time()
        
        # Session Handling (Extract session info from BigQuery)
        if request.session_id:
            # Retrieve existing session
            session = transaction_manager.get_session(request.session_id)
            if not session:
                print(f"Session {request.session_id} not found or expired. Creating new session.")
                session_id = transaction_manager.create_session(
                    user_id=request.user_id,
                    use_case=request.use_case,
                    slack_channel_id=request.slack_channel_id,
                    slack_thread_ts=request.slack_thread_ts,
                    metadata=request.metadata
                )
                session = transaction_manager.get_session(session_id)
            else:
                session_id = request.session_id
                print(f"Retrieved existing session {session_id}")
        else:
            # Create new session
            session_id = transaction_manager.create_session(
                user_id=request.user_id,
                use_case=request.use_case,
                slack_channel_id=request.slack_channel_id,
                slack_thread_ts=request.slack_thread_ts,
                metadata=request.metadata
            )
            session = transaction_manager.get_session(session_id)
            print(f"Created new session {session_id}")

        # Contextualization of the Question (LLM + History)
        conversation_history = session.get("conversation_history", [])
        original_query = request.query
        
        # Detect if this is a follow-up question
        is_followup = detect_followup_question(request.query)
        print(f"Follow-up question detected: {is_followup}")
        
        # Reformulate query with conversation history if needed
        if is_followup and conversation_history:
            contextualized_query = await reformulate_query_with_history(
                request.query, conversation_history, request.use_case
            )
            print(f"Query contextualized: '{request.query}' → '{contextualized_query}'")
        else:
            contextualized_query = request.query
            print(f"Using original query: '{request.query}'")
        
        # Knowledge Retrieval (ElasticSearch Layer)
        # Create a DPF Query object for the existing dpf_search function
        dpf_request = DPFQuery(
            query=contextualized_query,  # Use contextualized query for search
            use_case=request.use_case,
            index_name=request.index_name,
            k=request.k
        )
    
        # Use existing dpf_search function for retrieval
        search_result = await dpf_search(dpf_request)
        
        # Extract retrieved documents
        retrieved_docs = search_result.get("retrieved_documents", [])
        reranked_results = search_result.get("reranked_results", [])
        print(f"Retrieved {len(retrieved_docs)} documents, reranked {len(reranked_results)}")
        
        # Response Generation (LLM Layer with Conversation Context)
        # Build conversational context for LLM
        conversation_context = ""
        if request.include_history and conversation_history:
            conversation_context = build_conversational_context(conversation_history, original_query)
        
        # Get the LLM response from dpf_search result
        base_llm_response = search_result.get("llm_response", "")
        
        # Enhance response with conversational context if available
        if conversation_context and base_llm_response:
            # Add conversational awareness to the response
            enhanced_context = f"""
{conversation_context}
Retrieved Information:
{base_llm_response}
Please provide a response that acknowledges the conversation history and answers the current question contextually.
""" 
            # Use conversational context for better response
            try:
                headers = {
                    'Content-Type': 'application/json',
                    'X-apikey': DPF_API_KEY
                }
 
                payload = {
                    "useCase": "AIDER",
                    "contextId": DPF_CONVERSATION_CONFIG["conversation_context_id"],
                    "preSeed_injection_map": {
                        "{QUESTION}": enhanced_context
                    },
                    "parameters": {
                        "maxOutputTokens": DPF_LLM_CONFIG["max_output_tokens"]
                    }
                }
                
                response = requests.post(
                    DPF_ENDPOINTS["llm_endpoint"],
                    headers=headers,
                    data=json.dumps(payload)
                )
                response.raise_for_status()
                result = response.json()
                
                if isinstance(result, dict) and 'prediction' in result:
                    final_response = result['prediction']
                elif isinstance(result, str):
                    final_response = result
                else:
                    final_response = base_llm_response  # Fallback
                    
            except Exception as e:
                print(f"Conversational enhancement failed: {e}. Using base response.")
                final_response = base_llm_response
        else:
            final_response = base_llm_response
        
        # Calculate total pipeline time BEFORE logging
        total_time = time.time() - start_time
        
        try:
            # Log complete conversational transaction to BigQuery
            transaction_manager.log_conversational_transaction(
                session_id=session_id,
                original_query=original_query,
                contextualized_query=contextualized_query,
                response=final_response,
                retrieved_docs=reranked_results,
                api_response_time=total_time
            )
            print(f"Logged conversational transaction for session {session_id}")
        except Exception as e:
            print(f"Failed to log transaction: {e}")
        
        # Prepare Response (Back to Slack/User)
        search_result["search_metadata"]["total_pipeline_time"] = total_time
        
        # Add conversational metadata to response
        conversational_response = {
            **search_result,  # Include all original search results
            "conversational_metadata": {
                "session_id": session_id,
                "original_query": original_query,
                "contextualized_query": contextualized_query,
                "is_followup_question": is_followup,
                "conversation_turns": len(session.get("conversation_history", [])) + 1,
                "user_id": request.user_id,
                "slack_channel_id": request.slack_channel_id,
                "slack_thread_ts": request.slack_thread_ts,
                "total_processing_time": total_time
            },
            "llm_response": final_response  # Enhanced conversational response
        }
        
        print(f"Conversational pipeline completed in {total_time:.2f}s")
        return conversational_response
        
    except Exception as e:
        print(f"Conversational endpoint error: {e}")
        import traceback
        traceback.print_exc()
        return {
            "error": "Unable to process your conversational request at this time. Please try again.",
            "session_id": request.session_id,
            "conversational_metadata": {
                "error": str(e),
                "user_id": request.user_id
            }
        }

@app.get("/vegas/apps/aider-retriever/dpf/conversation/history/{session_id}")
async def get_conversation_history(session_id: str):
    """Get conversation history for a session from BigQuery transaction table"""
    try:
        session = transaction_manager.get_session(session_id)
        if not session:
            raise HTTPException(status_code=404, detail="Session not found")
        
        # Get conversation history from BigQuery for comprehensive view
        bigquery_history = transaction_manager.get_session_history_from_bigquery(session_id)
        
        return {
            "session_id": session_id,
            "user_id": session["user_id"],
            "conversation_history": session.get("conversation_history", []),  # Recent in-memory history
            "full_transaction_history": bigquery_history,  # Complete BigQuery history
            "session_info": {
                "created_at": session.get("created_at"),
                "use_case": session.get("use_case"),
                "is_active": session.get("is_active", True),
                "total_transactions": len(bigquery_history)
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/vegas/apps/aider-retriever/dpf/conversation/close/{session_id}")
async def close_conversation_session(session_id: str):
    """Close/end a conversation session"""
    try:
        session = transaction_manager.get_session(session_id)
        if not session:
            raise HTTPException(status_code=404, detail="Session not found")
        
        transaction_manager.close_session(session_id)
        
        return SessionResponse(
            session_id=session_id,
            user_id=session["user_id"],
            status="closed",
            message="Conversation session closed successfully",
            conversation_turns=len(session.get("conversation_history", []))
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    uvicorn.run("main_serve:app", host='0.0.0.0', port=2000, reload=True)
