#!/usr/bin/env python
# coding: utf-8

# In[1]:


import json
from typing import Dict, List, Type
import requests
from typing import Any
import warnings
warnings.filterwarnings("ignore")
import pandas as pd
# import gpudb
# from gpudb import GPUdbTable
import os
import time
from datetime import datetime


# In[ ]:


bearer = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VybmFtZSI6InJlZGR5dnUiLCJwbGF0Zm9ybSI6ImF1dG9iaSIsIlN0YXJ0IFRpbWUiOiIyMDI1LTA3LTE3IDE0OjMzOjEyIn0.dImi8mvrIBB415J03LUf0i6eKjdyoVevXiPPPURxoa4"
session_id = "0d7d5b47-5f0c-4613-a954-59b5dcca6f05"


# In[2]:


questions = pd.read_csv("query_output_validation.csv")
questions = questions[questions['Status'].str.strip().str.lower() != 'ignore']


# In[ ]:


def converse_and_extract(df_questions):
    """
    Makes API calls to the 'converse' endpoint for each question,
    extracts generated_query, history_id, and other relevant data.

    Args:
        df_questions (pd.DataFrame): DataFrame with 'question' and 'expected_query' columns.

    Returns:
        pd.DataFrame: DataFrame with question, expected_query, generated_query, history_id.
    """
    output_data_list = []
    converse_url = "https://qverse-api-dev.verizon.com/api/v1.0/genie/converse"
    headers = {
        'Content-Type': 'application/json',
        'Authorization': bearer,
        'X-Session-Id': session_id
    }

    # Use iterrows() correctly to get index and row data
    for index, row in df_questions.iterrows():
        question = row['question']
        expected_query = row['expected_query']

        payload_converse = json.dumps({
            "chatid": "string",
            "user_question": question,
            "domain": "Convoiq",
            "catalog": "Loyalty",
            "show_summary": "true",
            "show_visualization": "true",
            "temperature": 0
        })

        try:
            response = requests.post(converse_url, headers=headers, data=payload_converse, verify=False)
            response.raise_for_status() # Raise an exception for HTTP errors
            print(f"Converse API Response for '{question}': {response.status_code}")

            data_string = response.text
            # Split the string by 'data: ' and filter out empty strings
            entries = data_string.strip().split('\n\ndata: ')

            # Initialize variables for current iteration
            current_history_id = None
            current_generated_query = None
            current_tables_referred = None

            for entry in entries:
                if entry.startswith('{"event"'): # Ensure it's a JSON string
                    try:
                        data_dict = json.loads(entry)
                        if data_dict.get("event") == "history_id":
                            current_history_id = data_dict.get("data")
                        elif data_dict.get("event") == "tables_referred":
                            current_tables_referred = data_dict.get("data")
                        elif data_dict.get("event") == "generated_query":
                            current_generated_query = data_dict.get("data")
                    except json.JSONDecodeError as e:
                        print(f"Error decoding JSON in converse response: {e} in entry: {entry}")
            
            output_data_list.append({
                'question': question,
                'expected_query': expected_query,
                'generated_query': current_generated_query,
                'history_id': current_history_id,
                'tables_referred': current_tables_referred # Added tables_referred
            })

        except requests.exceptions.RequestException as e:
            print(f"Request error for question '{question}': {e}")
            output_data_list.append({
                'question': question,
                'expected_query': expected_query,
                'generated_query': None,
                'history_id': None,
                'tables_referred': None
            })
    
    return pd.DataFrame(output_data_list)


# In[ ]:


def get_catalog_rules(df_with_history):
    """
    Makes API calls to the 'query_feedback' endpoint for each row,
    extracts new and modified business rules.

    Args:
        df_with_history (pd.DataFrame): DataFrame containing 'history_id' and 'expected_query'.

    Returns:
        pd.DataFrame: Original DataFrame with an added 'rules_list' column.
    """
    catalog_rules_url = 'https://qverse-api-dev.verizon.com/api/v1.0/feedbacks/feedbacks/query_feedback'
    headers = {
        'Content-Type': 'application/json',
        'Authorization': bearer,
        'X-Session-Id': session_id
    }

    # Initialize a list to store business rules for each row
    rules_for_df = []

    for index, row in df_with_history.iterrows():
        history_id = row['history_id']
        expected_query = row['expected_query']
        
        # Initialize an empty list for the current row's rules
        current_business_rules_list = []

        if history_id is None:
            print(f"Skipping catalog_rules for row {index} due to missing history_id.")
            rules_for_df.append(None) # Append None if no history_id to indicate no rules found
            continue

        payload_catalog = json.dumps({
            "feedback": "false",
            "issues": [""],
            "nlp_feedback": " ",
            "historyid": history_id,
            "suggested_sql": expected_query
        })

        try:
            response = requests.post(catalog_rules_url, headers=headers, data=payload_catalog, verify=False)
            response.raise_for_status() # Raise an exception for HTTP errors
            print(f"Catalog Rules API Response for history_id {history_id}: {response.status_code}")

            data = json.loads(response.text)

            # Extract new rules
            new_rules = data.get('business_rules', {}).get('new_rules', [])
            for rule in new_rules:
                current_business_rules_list.append({
                    'rule_type': 'new',
                    'description': rule.get('description'),
                    'section': rule.get('section'),
                    'tables': rule.get('tables'),
                    'joins': rule.get('joins'),
                    'select': rule.get('select'),
                    'custom_dimensions': rule.get('custom_dimensions'),
                    'group_by': rule.get('group_by'),
                    'filters': rule.get('filters')
                })

            # Extract modified rules (only if there are any)
            modified_rules = data.get('business_rules', {}).get('modified_rules', [])
            if modified_rules:
                for rule in modified_rules:
                    current_business_rules_list.append({
                        'rule_type': 'modified',
                        'description': rule.get('description'),
                        'section': rule.get('section'),
                        'tables': rule.get('tables'),
                        'joins': rule.get('joins'),
                        'select': rule.get('select'),
                        'custom_dimensions': rule.get('custom_dimensions'),
                        'group_by': rule.get('group_by'),
                        'filters': rule.get('filters')
                    })
            
            rules_for_df.append(current_business_rules_list)

        except requests.exceptions.RequestException as e:
            print(f"Request error for history_id {history_id}: {e}")
            rules_for_df.append(None) # Append None if API call fails
        except json.JSONDecodeError as e:
            print(f"Error decoding JSON in catalog_rules response for history_id {history_id}: {e}")
            rules_for_df.append(None)

    # Add the collected rules list as a new column to the DataFrame
    df_with_history['rules_list'] = rules_for_df
    return df_with_history

