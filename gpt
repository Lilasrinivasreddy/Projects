import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from src.models.model_parameters import Parameters
from src.config_setup import Config
from src.utils.exceptions import GatewayTimeoutException, TooManyRequestsException
from src.utils.log_wrapper import logger_capture

class Gemini:
    def __init__(self, api_url: str, api_key: str):
        """
        Initializes the Gemini class with API URL and API key.

        Args:
            api_url (str): The URL of the API.
            api_key (str): The API key for authentication.
        """
        self.api_url = api_url
        self.api_key = api_key
        self.session = requests.Session()

        # Configure retries for the session
        retries = Retry(
            total=5, backoff_factor=0.3, status_forcelist=[429, 500, 502, 503, 504]
        )
        adapter = HTTPAdapter(max_retries=retries)
        self.session.mount("https://", adapter)
        self.session.mount("http://", adapter)

    def _call(self, session_logger,contextId, prompt_parameters: dict):
        """
        Makes a POST request to the API with the given prompt.

        Args:
            prompt (str): The prompt to send to the API.

        Returns:
            dict: The JSON response from the API.

        Raises:
            TooManyRequestsException: If the API returns a 429 status code.
            GatewayTimeoutException: If the API returns a 504 status code.
            Exception: For other non-200 status codes.
        """
        headers = {"Content-Type": "application/json", "X-apikey": self.api_key}
        # parameters = {"temperature": 0.0, "maxOutputTokens": 8192, "topP": 1}
        parameters = {
            "thinkingConfig": {
                "includeThoughts": Parameters.get_thoughts(),
                "thinkingBudget": 128# Parameters.get_thinkingbudget()
            },
            "temperature": Parameters.get_temperature(),
            "maxOutputTokens": 8192,
            "topP": 1
        }
        safety_settings = [
            {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_CIVIC_INTEGRITY", "threshold": "BLOCK_NONE"},
        ]
        json_data = {
            "useCase": "qverse_pro",
            "contextId": contextId,
            "preSeed_injection_map": prompt_parameters,
            "parameters": parameters,
            "safetySettings": safety_settings,
        }

        try:
            logger_capture.log_debug(
                    session_logger,f"Calling Vegas API with Context ID:{contextId} using model Gemini 2.5 Pro")
            response = self.session.post(
                self.api_url, headers=headers, json=json_data, verify=False
            )
        except Exception as e:
            logger_capture.log_error(
                    session_logger,f"failed to go to vegas due to:{e}")

        if response.status_code == 429:
            logger_capture.log_error(
                session_logger, f"Vegas Failed with 429 response:{response.json()}"
            )
            raise TooManyRequestsException(transaction_id=response.json())
        elif response.status_code == 504:
            logger_capture.log_error(
                session_logger, f"Vegas Failed with 504 response:{response.json()}"
            )
            raise GatewayTimeoutException(transaction_id=response.json())
        elif response.status_code == 200:
            output = response.json()
            return output

        else:
            logger_capture.log_error(
                session_logger,
                f"Vegas Failed with error code {response.status_code} with response {response.json()}"
            )
            raise Exception(f"Vegas Failed with error code {response.status_code}")

    def _llm_type(self) -> str:
        """
        Returns the type of the LLM.

        Returns:
            str: The type of the LLM.
        """
        return "gemini_pro"


# Initialize the Gemini instance with the configured API URL and key

gemini_pro_llm = Gemini(api_url=Config.llm.vegas_llm, api_key=Config.llm.vegas_api)
