import logging
import os
import sys
import argparse
from sqlalchemy import create_engine
from google.cloud import bigquery
import google.auth

# Import configuration from the config folder
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '../config')))
from config import CONFIG  # Import config settings

# Import CommonUtils class from your existing script
from your_existing_script import CommonUtils  # Replace with your actual script name

# Configure Logging
logging.basicConfig(
    format='%(asctime)s : %(levelname)s : %(message)s',
    level=logging.INFO
)

class QueryExecutor:
    def __init__(self, logger):
        self.config = CONFIG  # Load configuration
        self.logger = logger
        self.utils = CommonUtils(self.config, logger)  # Use existing connection functions

    def execute_query(self, db_type, query):
        """
        Execute Query based on the database type.
        :param db_type: 'TD' for Teradata, 'GCP' for BigQuery
        :param query: SQL query to execute
        """
        try:
            if db_type.upper() == "TD":
                return self.execute_teradata_query(query)
            elif db_type.upper() in ["GCP", "BQ"]:
                return self.execute_bigquery_query(query)
            else:
                self.logger.error(f"Invalid database type: {db_type}")
        except Exception as e:
            self.logger.error(f"Error executing query for {db_type}: {e}")

    def execute_teradata_query(self, query):
        """Execute SQL query in Teradata"""
        td_engine = self.utils.teradata_client(self.config["teradata"], self.config["teradata"]["database"])
        if not td_engine:
            self.logger.error("Failed to connect to Teradata.")
            return None
        try:
            self.logger.info(f"Executing Teradata Query: {query}")
            with td_engine.connect() as conn:
                conn.execute(query)
            self.logger.info("Teradata Query Execution Successful")
        except Exception as e:
            self.logger.error(f"Error executing Teradata Query: {e}")
        finally:
            td_engine.dispose()

    def execute_bigquery_query(self, query):
        """Execute SQL query in BigQuery"""
        bq_client, _ = self.utils.bigquery_client(self.config["bigquery"])
        if not bq_client:
            self.logger.error("Failed to connect to BigQuery.")
            return None
        try:
            self.logger.info(f"Executing BigQuery Query: {query}")
            query_job = bq_client.query(query)
            query_job.result()  # Waits for the query to finish
            self.logger.info("BigQuery Query Execution Successful")
        except Exception as e:
            self.logger.error(f"Error executing BigQuery Query: {e}")

if __name__ == "__main__":
    # Initialize Logger
    logger = logging.getLogger("QueryExecutor")

    # Initialize Query Executor
    executor = QueryExecutor(logger)

    # Setup Argument Parser
    parser = argparse.ArgumentParser(description="Execute SQL Queries Dynamically")
    parser.add_argument("--db_type", required=True, help="Database type: TD (Teradata) or GCP (BigQuery)")
    parser.add_argument("--query", required=True, help="SQL query to execute (enclose in quotes)")

    args = parser.parse_args()

    # Execute the query dynamically based on input
    executor.execute_query(args.db_type, args.query)
