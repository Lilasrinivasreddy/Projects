import requests
import json
import os
api_url = "https://vectordb-experimentation-np.ebiz.verizon.com"
api_key = "S0tWX1hKY0I1cVU4UlpJMHdPUWM6YjdubXYyNnJSbi1aek9BQkdEck5jQQ=="
index_name = "jysv-dpf-dev1"
os.environ['DEV_API_KEY'] = 'noio4yaGDAUnSk8zo1J42j3pJHHXLqBl'
os.environ['UAT_API_KEY'] = 'tHg4R3CFo74nGbAjHONOgPg2iHZS2L96'
os.environ['EMBEDDING_ENDPOINT'] = 'https://oa-dev2.ebiz.verizon.com/vegas/models/llm-embeddings'
# os.environ['VECTOR_SEARCH_ENDPOINT'] = 'https://oa-dev2.ebiz.verizon.com/vegas/vector-search/generic-v1/api'
os.environ['CROSS_ENCODER_ENDPOINT'] = 'https://oa-uat.ebiz.verizon.com/vegas/models/api'
os.environ['LLM_ENDPOINT'] = 'https://oa-uat.ebiz.verizon.com/vegas/apps/prompt/LLMInsight'


# 1. Generate Embedding
embedding_response = requests.post(os.environ['EMBEDDING_ENDPOINT'], 
                                   headers={'X-apikey': os.environ['DEV_API_KEY'],'Content-Type': 'application/json'}, 
                                   data=json.dumps({
                                       "text" : user_query,
                                       "model_name" : 'all-distilroberta-v1'}))
embedding = embedding_response.json()
print("-------------------------------")
print("Embedding Results:\n")
# print("Generated Embedding:", embedding[:20])
print("Dimensions of the Generated Embedding:", len(embedding))



# 2.2 Perform Elastic Search
query = {
                "_source": [],
                "query": {
                    "bool": {
                    "filter": [
                                {
                                "term": {
                                    "usecase_name": "aider"
                                }
                                }
                            ],
                    "should": [
                        {
                        "knn": {
                            "field": "text_embedding_768",
                            "query_vector": embedding,
                            "k": 10,
                            "num_candidates": 100
                        }
                        }
                    ]
                    }
                }
    }
def search_elasticsearch(api_url, api_key, index_name, query):
    """
    Retrieve chunks from an Elasticsearch index based on a query.

    :param api_url: The base URL of the Elasticsearch instance.
    :param api_key: The API key for authentication.
    :param index_name: The name of the Elasticsearch index.
    :param query: The query to search for.
    :return: The search results.
    """
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"ApiKey {api_key}"
    }

    search_url = f"{api_url}/{index_name}/_search"
    print("search",search_url)
    payload = query

    try:
        response = requests.post(search_url, headers=headers, data=json.dumps(payload))
        response.raise_for_status()  # Raise an error for HTTP codes 4xx/5xx
        return response.json()
    except requests.exceptions.RequestException as e:
        print(f"Error querying Elasticsearch: {e}")
        return None
    
elastic_search_results = search_elasticsearch(api_url, api_key, index_name, query)['hits']['hits']
# print(elastic_search_results)

elastic_search_results_contexts = [contexts.get('_source').get('chunk_data') for contexts in elastic_search_results]
print("-------------------------------")
print("Elastic Search Results:\n")
for ele in elastic_search_results:
    print(json.dumps(ele))




# 3. Re-rank Results
sentence_pairs = [[user_query, context] for context in elastic_search_results_contexts]
reranker_response = requests.post(os.environ['CROSS_ENCODER_ENDPOINT'], 
                                  headers={'Content-Type': 'application/json', 'X-apikey': os.environ['UAT_API_KEY']}, 
                                  data=json.dumps({
    "region": "us-east4",
    "project_id": "688379114786",
    "endpoint_id": "4179014998757998592",
    "usecase_name": "cross-encoder",
    "model_type": "cross-encoder",
    "input_request": {
        "instances": sentence_pairs
    }
}))



reranked_results = reranker_response.json()
cross_scores = reranked_results[0][0].get("prediction_scores")
context_list  = []
for score, context in zip(cross_scores, elastic_search_results):  
    reranked_dict = {}
    reranked_dict['cross_score'] = score
    reranked_dict['text'] = context
    context_list.append(reranked_dict) 

# define number of output documents
# define number of output documents
docs = sorted(context_list, key=lambda x:x["cross_score"], reverse=True)
print("-------------------------------")
print("Reranked Results:\n")
for ele in docs:
    print(ele) 

top_doc = max(docs, key=lambda x: x['cross_score'])
top_doc_context = top_doc['text']
print("-------------------------------")
print("Top document:\n")
print(top_doc_context)




# 4. Get LLM Response
llm_response = requests.post(os.environ['LLM_ENDPOINT'], 
                             headers={'Content-Type': 'application/json', 'X-apikey': os.environ['UAT_API_KEY']}, 
                             data=json.dumps({
        "useCase": "AIDER",
        "contextId": "AIDER_CONTEXT",
        "preSeed_injection_map": {
        "{CONTEXT}": top_doc_context,
        "{QUESTION}": user_query
    }
}))

final_llm_response = llm_response.json()
print("-------------------------------")
print("Final Repsponse:\n")
print(f"Final LLM Response for the user query is :", final_llm_response.get('prediction'))
