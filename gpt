def load_to_report_results(self, df_report_result: pd.DataFrame, reference_key: str):
    try:
        ## BigQuery Client Connection
        dbclient, db_creds = self.utils.bigquery_client(
            auth=config.dq_gcp_auth_payload
        )

        # Remove duplicate columns
        df_report_result = df_report_result.loc[:, ~df_report_result.columns.duplicated()]
    
        df_report_result["rpt_ref_key"] = reference_key

        # Debugging Step: Log existing columns before fixing
        self.logger.info(f"Columns before checking 'consistecy_score': {df_report_result.columns.tolist()}")

        # Ensure 'consistecy_score' is present (Fixing the Error)
        if 'consistecy_score' not in df_report_result.columns:
            self.logger.warning("Column 'consistecy_score' missing, adding it with default value 0.")
            df_report_result['consistecy_score'] = 0.0  # Default value

        # Debugging Step: Log existing columns after adding 'consistecy_score'
        self.logger.info(f"Columns after fixing missing values: {df_report_result.columns.tolist()}")

        # Convert Numeric Columns to Correct Data Types
        numeric_columns = [
            "avg_count_prev", "variance_value", "std_dev_value", "sigma_2_value",
            "pct_change", "count_curr", "dq_score", "min_thresh_value", "max_thresh_value", "consistecy_score"
        ]
        for col in numeric_columns:
            if col in df_report_result.columns:
                df_report_result[col] = pd.to_numeric(df_report_result[col], errors='coerce')

        # Convert Integer Columns (Fixing String Issue)
        int_columns = ["weekday", "prfl_id", "rpt_seq_num", "dq_score"]
        for col in int_columns:
            if col in df_report_result.columns:
                try:
                    df_report_result[col] = df_report_result[col].astype(int)
                except Exception as e:
                    self.logger.error(f"Error converting column '{col}' to int: {e}")
                    self.logger.info(f"Problematic Column '{col}' Values: {df_report_result[col].unique()}")

        # Convert Date/Datetime Columns
        datetime_columns = ["data_dt", "insert_date", "prfl_run_ts"]
        for col in datetime_columns:
            if col in df_report_result.columns:
                df_report_result[col] = pd.to_datetime(df_report_result[col], errors='coerce')

        self.logger.info("--------Data Types After Fixing:\n%s", df_report_result.dtypes)

        # Debugging Step: Check for NaN values in numeric columns
        nan_counts = df_report_result[numeric_columns].isna().sum().sum()
        if nan_counts > 0:
            self.logger.warning(f"Warning: Some numeric values contain NaNs! Count: {nan_counts}")

        # Debugging Step: Log columns before BigQuery Load
        self.logger.info(f"Columns before BigQuery Load: {df_report_result.columns.tolist()}")

        ## Loading Table Level Report
        self.utils.load_result_to_bq_report_table(
            dq_bq_client=dbclient,
            dq_credentials=db_creds,
            dq_report_table_name=config.dqaas_profile_rpt,
            df_load_data=df_report_result,
            seq_name='rpt_seq_num',
            column_details=self.custom_profile_report_columns
        )
        
    except Exception as err:
        self.logger.error(f"Error in load_to_report_results: {err}")
