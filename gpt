(0:00) Right, right, yes. (0:03) Yeah, so he basically sends five requests at once, then 30 requests and then 25 requests or something. (0:08) Yes, yes, yes, yeah, I do know.
(0:09) So, we have that as a separate script right now. (0:13) Okay, okay. (0:14) So, what are we going to do is, we will create a framework.
(0:18) Okay. (0:19) Okay, we call it a test framework, where you have this load or balance testing as one component. (0:27) Okay, okay.
(0:28) Then the second component would be accuracy testing, where you have some golden set of (0:32) questions defined for each domain catalog. (0:34) And you will just click, you'll have a button saying that, you know, run test. (0:39) Okay.
(0:40) You go back in the backend, you run some tests on those golden set of questions, (0:44) you do the accuracy comparison, come back with the results. (0:48) Okay, okay. (0:48) Even the load balance testing also the same, like if I select a batch number, (0:52) like if I say batch 20, then you send 20 requests at once, (0:55) do the load testing and come back with the results.
(0:59) Okay, okay. (1:00) Right. (1:01) All of these results, you'll store it in a database, you'll keep track of it.
(1:06) And then, you know, you can have a dashboard where you can come and monitor your performance, (1:10) like day to day, like, you know, over time, however, how many of this you do, (1:15) you can see how your tool is performing. (1:18) Okay. (1:19) Right.
(1:20) So, if we can build that as a complete dashboard. (1:24) Okay, okay. (1:26) Which will again have the domain catalog section divided, right? (1:30) We'll have it at entire Q-verse level and then we'll put some filters for domains and catalogs.
(1:35) And any coming in, like any admin coming in, (1:38) they can view the results for their particular domain catalog. (1:42) Okay, okay. (1:43) So, in the existing Q-verse framework only, that will be right, Akesh? (1:48) Yeah, within existing Q-verse only, we'll do it.
(1:53) Okay, okay. (1:54) On Q-verse, we have one small dashboard, right? (1:56) On the homepage, you have four charts that we show. (1:59) Yes, yes, yes.
(2:00) Yeah, if we mark the underscore, that breakdown, (2:04) markdown button, then we will get it, I think, charts. (2:09) Right, yeah. (2:10) So, now instead of those charts, I mean, those charts will still be there, (2:15) but we'll bring in this complete framework in place.
(2:18) Okay. (2:18) Those charts are basically giving you user level history, right? (2:21) We'll create two more screens, one for catalog history and then system level history. (2:27) And on top of that, we'll add the second dashboard for our testing.
(2:30) Okay, okay. (2:32) Got it, Akesh. (2:33) All right, so this, you have the entire analytics of your platform, right? (2:37) Okay, okay.
(2:40) So, I thought if you could work on this, (2:42) but then if you are occupied with something else for next two days, then... (2:47) The thing is, I want you and Yogesh to work on this, both of you. (2:50) Okay. (2:51) It's going to be good.
(2:52) So, Monday I can work, Akilesh. (2:55) Like, as I said, right, like, how I am doing is, see, generally in the morning session, (2:59) I complete my regular thing. (3:02) From afternoon session, I start working on keywords.
(3:04) So, that's how I used to split. (3:09) So, actually, I can start on Monday, but... (3:13) If you can start on Monday, then I think it's fine. (3:15) But the target was, the way I was thinking is, (3:20) we'll use it in two days or three days max, (3:22) because it's going to be just APIs, (3:25) like there's no functionality there.
(3:26) It's just APIs that you're writing. (3:28) And the scripts are already there. (3:29) Okay, okay.
(3:30) So, I got two or three days. (3:32) But again, if you need some time, if you're occupied with something else, (3:34) you can give an additional day, I guess. (3:37) Yeah, mostly I can start on Monday.
(3:41) I will try to finish, Akilesh, like by Tuesday only. (3:44) But Tuesday night, I have one again. (3:47) There is one more release.
(3:50) So, it's like I cannot completely sit 50%, I can say. (3:55) But yeah, I will try to complete by Tuesday only. (3:57) I will target for Tuesday, better.
(3:59) Tuesday or max Wednesday then. (4:02) Okay, okay. (4:03) Yeah, you have Yogesh also, right? (4:05) I mean... (4:06) Yeah, Yogesh Gupta, right? (4:07) Yeah, yeah.
(4:08) Okay, okay. (4:09) I will connect with him. (4:11) I didn't get a chance to talk to him today.
(4:13) So, you know, you had a chance either probably on Monday morning, right? (4:17) Uh-huh, sure. (4:17) So, even he will be working on FATEL for the LSP testing. (4:20) He's working day to day.
(4:21) So, Monday, I think he can also start on Monday. (4:25) Okay, okay. (4:27) So, if both of you can build those APIs and bring the dashboards.
(4:30) Because he's the one who has that script. (4:32) Okay, okay. (4:32) For batch testing.
(4:34) Okay, okay, Akilesh. (4:35) I will ask him regarding that. (4:38) Okay, got it, Akilesh.
(4:42) So, when you do it, right, just think of various filters you can put on the API, (4:46) like domain catalog or no filter at all. (4:48) Or like, you know, where exactly you need filters. (4:51) And also, if you're doing a test pipeline, accuracy testing, right? (4:54) Then you will put our domain catalog filter.
(4:57) Okay, okay. (4:58) Because you're picking any golden questions for that particular domain catalog. (5:02) Then if you're doing a load balancing testing, (5:04) then you don't have to put any domain catalog, right? (5:06) It's just an overall tool that you're looking at.
(5:08) Okay, okay. (5:09) So, we'll just, when we say batch of 30, (5:12) we'll send random domains, catalogs and the 30 requests. (5:16) Okay.
(5:17) Something like that. (5:18) Okay, okay, yeah. (5:20) So, I will connect with Yogesh and I will get that script.
(5:24) So, the major thing is this filter part, we have to work on the backend. (5:31) Okay, okay. (5:32) Yeah, he will have the hardcoded request body.
(5:36) Instead, you'll have to get it on API. (5:38) Okay, okay, yeah, I understand. (5:42) Sure, Aklesh.
(5:43) Yeah, I will connect with him and I will let you know. (5:46) If anything is there, I will connect on Monday. (5:49) At least I will start and implement some thing part.
(5:54) This API part, I can start, I think. (5:57) So, yeah, then we can get a clear idea and Monday we can discuss on that, Aklesh. (6:03) Okay, okay.
(6:04) And if you want to write, I mean, maybe do it this way. (6:10) Don't put it on QoS yet. (6:12) Just create it as a separate tool.
(6:15) Okay, okay. (6:17) We'll host it as an API for now. (6:19) Okay, okay.
(6:19) We'll create a QoS. (6:22) Okay, okay. (6:23) We'll review, we'll use it as POC and then integrate with QoS.
(6:28) Okay, Aklesh, I understand. (6:30) Yeah, sure, sure. (6:32) Sure, Aklesh.
(6:34) Anything else, Aklesh? (6:37) Aklesh, that Vega part, have you tested, Aklesh? (6:40) I didn't got much chance. (6:41) I have deployed it. (6:43) No, no, no.
(6:43) This LSP branch is still in dev. (6:46) Okay. (6:46) So, I'm not able to test it.
(6:48) Okay, I was also... (6:51) Oh, yeah, this LSP, everyone is busy, I think. (6:54) Even in the calls also. (6:57) Yeah, if only LST goes into next stage, we can test this.
(7:00) We planned Vega and Prod today, but I don't know LSP is taking up all the space. (7:07) And what happened to this talk-to-report? (7:10) They are not even discussing on that talk-to-report part? (7:13) No, talk-to-report, the canvas, Yogesh was building a canvas for talk-to-report. (7:20) The dashboard screen that he was sharing earlier, I think, (7:24) I don't know, not yesterday, I don't think, but day before yesterday, I think.
(7:28) Oh, okay, okay. (7:29) So, that was for talk-to-report. (7:32) Yeah, that's what it is.
(7:34) You can save it as PDF and all of that.
===========
conversation 2
(0:17) This should be like a dashboard, however, any example like looker dashboard or whatever (0:28) we take, it should be a kind of dashboard where we have to show the filters as well (0:36) as. (0:38) So, this testing whatever latency testing is doing, those results only we need to show (0:43) right at this. (0:45) Correct, latency testing and also accuracy testing.
(0:48) Yeah, latency and accuracy. (0:49) So, what you wish to do is latency, yeah. (0:51) So, what you wish to do is latency, but you will have accuracy testing also.
(0:55) Okay. (0:55) Right. (0:56) And based on that accuracy testing you can do this.
(0:58) Okay. (0:58) So, one thing is, one more thing, for this accuracy testing we need golden questions. (1:05) Golden questions, right.
(1:06) Yes. (1:08) So, for the golden questions what we can do is on the UI itself for any domain catalog. (1:14) Okay.
(1:14) We will give an option to upload a csv file which has the questions and SQL queries. (1:20) Okay. (1:21) Right.
(1:22) We will take that csv file, store that csv file in gcp bucket. (1:27) Okay. (1:28) Okay.
(1:28) So, we will put it in a gcp bucket and in that gcp bucket we will create a folder called (1:33) golden questions and in that golden questions we will create a domain catalog folder and (1:37) in that domain catalog we will have that particular csv file. (1:41) Okay. (1:42) And there also we can give the golden questions which are specific name . We will create folder (1:44) and add a standard format.
(1:48) We will put it on gcp bucket. (1:50) Right. (1:50) Okay.
(1:50) Now whenever someone comes to do the test they can just say run test, it will go back (1:54) in the gcp bucket, pull that file, run the accuracy test check. (1:58) Okay. (1:59) Okay.
(2:00) And one more question, here whatever yogesh script, right, there we will be getting the (2:05) complete details in a csv format. (2:07) So, there also we have the questions, right, golden questions. (2:11) So, that way we can use it? (2:13) Right.
(2:15) You can use the same data. (2:17) Okay. (2:17) Okay.
(2:19) Okay. (2:22) Understand. (2:22) Understand.
(2:23) And also, in terms of dashboard, you want me to show like anything, anything like, you (2:28) know, trend or trend, some time series analysis, those kind of charts are sufficient. (2:34) That's right. (2:35) Okay.
(2:35) Okay. (2:36) Correct. (2:36) So, on do nothing, forget about UI for now, just go and go to the backend, take the latest (2:43) backend and ask for trend or the QoS development or anything.
(2:47) Okay. (2:47) Or you can also take, okay, there's a new branch, I think it's a branch name, it already (2:52) has the GCP bucket storage port. (2:54) Okay.
(2:54) Okay. (2:55) Okay. (2:55) Okay.
(2:56) The code is already there. (2:57) So, there is a helper function where you can just call the function with the CSV file (3:01) or whatever details, right. (3:02) and it will upload the file in that particular folder structure (3:07) okay (3:08) so you can take that code, you can create your own (3:12) like you know, in the routers where we have (3:15) genie reports, you can create a new router (3:17) or a test framework or something (3:19) yeah, okay (3:20) and on the test, you can create a test framework and add your APIs to it (3:25) okay, okay, I understand (3:27) okay, okay (3:28) yeah, I mean (3:29) eventually I think we need to bring it out and operate too (3:32) but for now, I'm just thinking (3:35) or even if you think you can do it as a separate tool, that's totally fine (3:40) like if you think of creating as a separate tool, it's easier to do that (3:43) take whatever code references you need from QoS (3:46) like for the storage bucket, so you know, type of creations, not database connections (3:50) take your RFNs tool and put it in your script (3:54) okay, okay, got it, got it (3:56) sure Akhilesh, I started, I mean (3:58) I was also occupied with other work like (4:01) this morning I was in continuous calls and other tasks (4:03) so probably by this weekend, like by Friday (4:06) we will make it as a target, Akhilesh (4:09) tomorrow I have some time, so I will start completely focusing (4:12) almost 80% I can focus on this (4:15) so we can have a review tomorrow (4:18) but by Friday, I will try to finish it (4:22) yeah, yeah, try to do that (4:23) and since enough code file is not read (4:26) what you can do is (4:28) give the QoS, whatever branch I will share (4:31) just give that branch to QoS store (4:34) and tell it that, you know, use those code pieces as a reference (4:38) to create a new tool by itself (4:41) instead of putting on QoS, just ask it to create a new tool (4:44) just give it all the functionalities (4:46) so what I do is, I create a .md file (4:48) where I give, you know, phase 1, phase 2, phase 3 instructions to it (4:53) so that way it will just follow and also try that (4:56) and since you are making it as a sub-trade framework (5:00) you can also add a filter for environment (5:05) like if you want to do the testing on dev environment (5:07) you can do that, if you want to do it on PLU (5:09) you can do that, if you want to go to prod trade (5:10) just switch the APIs to prod (5:13) so you will have one framework which can connect to all the three environments (5:18) and you just switch, you give the user the option to switch (5:23) ok, ok Akhilesh, got it (5:26) sure Akhilesh, I will check that (5:31) ok, you can share those details (5:34) I will share that, yeah (5:37) sure Akhilesh, I will connect more (5:39) yeah, only thing is your GCP bucket (5:42) it might not work in dev, it might just throw you an error saying (5:45) file not saved or something (5:47) so you will have to use prod GCP account for that (5:52) ok, and I also think I won't get any kind of access to the GCS bucket (5:59) personal access, no I don't think so (6:02) yeah, I won't get it (6:03) so let me test it tomorrow so I will come to know (6:08) like whether any kind of error (6:11) on logs if it says it successfully uploaded, I think it's fine (6:15) when I come back, we can now look at it (6:19) ok, sure Akhilesh, I will connect more (6:24) ok, ok (6:26) thank you Akhilesh, bye (6:28) thanks


========
conversation 3
(0:04) So, let us see if you can connect with Anjali, I think she is going to come back in an hour (0:16) she is off right now. (0:17) Sure, sure, I will connect with her, I will check on that accuracy part. (0:21) So, the same thing I have to integrate over here, right? (0:24) Right, same thing, yes.
(0:26) It is again, it is just an LLM approach, so you will have to just create a prompt, call (0:30) this and you know, generate it. (0:32) So, we can do that. (0:34) Okay.
(0:35) Other thing is, Anirban had some other metrics as well, right, that he wanted to bring in. (0:41) So, maybe Yogi, you can check with Anirban what are the metrics you wanted to see and (0:44) you know, you can bring those in. (0:49) Okay.
(0:50) Yeah, just double check with Anirban, right, once, what metrics you wanted. (0:54) Probably have the issue cut first before going to Anirban, just have the issue cut first. (0:57) So, I will just show him what, you know, whatever we discussed in Baltimore and then (1:01) ask him for the additional tricks.
(1:04) Sure, Aklesh. (1:06) Okay. (1:10) So, that is good.
(1:11) So, no other blockers, right? (1:13) Only the DB connections I need to cross check once again, because this CSV file, how we (1:18) are, other than that, nothing Aklesh. (1:22) Okay. (1:22) I will inform you in a while regarding that.
(1:25) Okay. (1:27) Okay, good. (1:27) CSP file is one thing right, but this golden questions you are currently pulling it from CSP right as part of the framework? (1:34) So this CSP, from that script, whatever Yogesh is running that script for testing right.
(1:40) So that CSP sample I have taken. (1:41) Okay, okay that's fine. (1:44) So what we'll do is once you have that right, we'll put it on the GCP bucket and read it from there.
(1:49) Rather than from CSP file right, we'll read the golden set of questions from GCP buckets based on domains and categories. (1:55) Okay, yeah got it. (1:56) Yeah, okay.
