import os
import json
import logging
import pandas as pd
import time
import requests
import teradatasql
from google.cloud import bigquery
import google.auth
import pandas_gbq
from django.http import JsonResponse
from django.views.decorators.csrf import csrf_exempt
from django.utils.decorators import method_decorator
from django.views import View
import re

# ‚úÖ Teradata Configuration
dq_td_config = {
    "hostname": "TDDP.TDC.VZWCORP.COM",
    "uid": "IDQPRDLD",
    "pwd": "Newpass#969",
    "dbname": "idq_prd_tbls"
}

# ‚úÖ Google BigQuery Configuration
dq_config = {
    "sa_json_file_dtls": os.path.join(os.path.dirname(__file__), "sa-pr-izcv-app-idmcdo-0-oidc-27472-config.json"),
    "conn_project_id": "vz-it-pr-izcv-idmcdo-0",
    "bq_table_name": "your_project.your_dataset.dqaas_profile_rpt"  # ‚úÖ Replace with actual BigQuery table
}

# ‚úÖ Initialize Logging
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)

# ‚úÖ Connect to Teradata
def teradata_client():
    try:
        logger.info("üîÑ Connecting to Teradata...")
        conn = teradatasql.connect(
            host=dq_td_config["hostname"],
            user=dq_td_config["uid"],
            password=dq_td_config["pwd"],
            database=dq_td_config["dbname"]
        )
        logger.info("‚úÖ Teradata connection successful!")
        return conn
    except Exception as err:
        logger.error(f"‚ùå Teradata connection failed: {err}")
        return None

# ‚úÖ Connect to Google BigQuery
def bigquery_client():
    os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = dq_config["sa_json_file_dtls"]
    os.environ['GOOGLE_CLOUD_PROJECT'] = dq_config["conn_project_id"]
    credentials, _ = google.auth.default()
    return bigquery.Client(credentials=credentials, project=dq_config["conn_project_id"]), credentials

# ‚úÖ Fix SQL Query Formatting for Teradata
def fix_query_format(query):
    logger.info(f"üîç Fixing SQL Query Formatting:\n{query}\n")
    
    # ‚úÖ Wrap schema/table names with hyphens in double quotes
    fixed_query = re.sub(r'(\b[a-zA-Z0-9_-]+-[a-zA-Z0-9_-]+\b)', r'"\1"', query)

    logger.info(f"‚úÖ Fixed Query:\n{fixed_query}\n")
    return fixed_query

# ‚úÖ Function to Load DataFrame to BigQuery
def load_result_to_bq(df_load_data):
    try:
        logger.info(f"üìå Loading results into BigQuery table: {dq_config['bq_table_name']}")
        
        if df_load_data.empty:
            logger.warning(f"‚ö†Ô∏è No data to insert into BigQuery for table {dq_config['bq_table_name']}")
            return
        
        # ‚úÖ Ensure column names are lowercase
        df_load_data = df_load_data.rename(columns={col: col.lower() for col in df_load_data.columns})
        
        pandas_gbq.to_gbq(
            dataframe=df_load_data,
            destination_table=dq_config["bq_table_name"],
            if_exists="append",
            project_id=dq_config["conn_project_id"],
        )
        logger.info(f"‚úÖ Successfully loaded {len(df_load_data)} rows into {dq_config['bq_table_name']}")
    except Exception as err:
        logger.error(f"‚ùå Error loading results into BigQuery: {err}")

# ‚úÖ Extract `SELECT` Query from `INSERT INTO ... SELECT`
def extract_select_query(insert_query):
    try:
        # ‚úÖ Find the position of 'SELECT' in the query
        select_index = insert_query.lower().index("select")
        select_query = insert_query[select_index:].strip()
        return select_query
    except ValueError:
        return None  # No SELECT found

# ‚úÖ Process SQL File Upload and Execute Queries
@method_decorator(csrf_exempt, name="dispatch")
class ExecuteHistorySQL(View):
    def post(self, request):
        try:
            logger.info(f"üìÇ Received FILES: {request.FILES}")

            if "file" not in request.FILES:
                return JsonResponse({"status": "failure", "message": "No file uploaded."}, status=400)

            file = request.FILES["file"]
            queries = file.read().decode("utf-8").strip().split(";")
            results = {}

            for query in queries:
                query = query.strip()
                if not query:
                    continue

                # ‚úÖ Fix Query Format
                query = fix_query_format(query)
                logger.info(f"üìå Executing Fixed Query:\n{query}")

                try:
                    conn = teradata_client()
                    if conn is None:
                        return JsonResponse({"status": "failure", "message": "Teradata connection failed."}, status=500)

                    cursor = conn.cursor()

                    # ‚úÖ Extract Data from Teradata (SELECT Query Inside INSERT)
                    if "insert into" in query.lower():
                        select_query = extract_select_query(query)

                        if not select_query:
                            logger.error("‚ùå No SELECT statement found in the INSERT query.")
                            return JsonResponse({"status": "failure", "message": "No SELECT found in INSERT."}, status=500)

                        logger.info(f"üìå Extracted SELECT Query:\n{select_query}")

                        # ‚úÖ Execute SELECT Query in Teradata
                        cursor.execute(select_query)
                        results_list = cursor.fetchall()

                        if not results_list:
                            logger.warning(f"‚ö†Ô∏è Query returned no data: {query}")
                            continue  # Skip processing if no results

                        df = pd.DataFrame(results_list, columns=[desc[0] for desc in cursor.description])
                        cursor.close()
                        conn.close()

                        # ‚úÖ Insert Data into BigQuery
                        load_result_to_bq(df)

                        results[query[:30]] = f"‚úÖ Data inserted successfully in BigQuery. {len(df)} rows."

                    else:
                        logger.error(f"‚ö†Ô∏è Skipping invalid query: {query}")

                except Exception as e:
                    logger.error(f"‚ùå Query execution failed: {query}\nError: {e}")
                    return JsonResponse({"status": "failure", "message": str(e)}, status=500)

            return JsonResponse({"status": "success", "results": results}, status=200)

        except Exception as e:
            logger.error(f"‚ùå Error processing request: {e}")
            return JsonResponse({"status": "failure", "message": str(e)}, status=500)


March 20, 2025 - 21:56:48
Django version 5.1.1, using settings 'dqaas_api.settings'
Starting development server at http://127.0.0.1:8000/
Quit the server with CTRL-BREAK.

2025-03-20 21:57:01,332 - INFO - üìÇ Received FILES: <MultiValueDict: {'file': [<InMemoryUploadedFile: file.txt (text/plain)>]}>
2025-03-20 21:57:01,333 - INFO - üîç Fixing SQL Query Formatting:
insert into vz-it-np-izcv-dev-idmcdo-0.dga_dq_tbls.dqaas_profile_rpt
(rpt_seq_num, prfl_id, prfl_type, dq_pillar, src_tbl, meas_name, data_dt, feature_name, grouped_columns, count_curr, prfl_run_ts, weekday)
(select 900098 as rpt_seq_num, 7851 as prfl_id, 'CUSTOM_RULES' as prfl_type, 'Consistency' as dq_pillar, 'CUST_ACCT_LINE_ADDR_V' as src_tbl,'CUST_ACCT_LINE_ADDR_V Table count' as meas_name,
cast(LAST_UPD_DT as date) as data_dt,'Tier1 Models' as feature_name, null as grouped_columns,count (*) as count_curr, current_timestamp as prfl_run_ts,
dayofweek(cast(LAST_UPD_DT as date)) as weekday from NTL_PRD_ALLVM.CUST_ACCT_LINE_ADDR_V where cast(LAST_UPD_DT as date)>= current_date -90
group by 1,2,3,4,5,6,7,8,11,12)

2025-03-20 21:57:01,334 - INFO - ‚úÖ Fixed Query:
insert into "vz-it-np-izcv-dev-idmcdo-0".dga_dq_tbls.dqaas_profile_rpt
(rpt_seq_num, prfl_id, prfl_type, dq_pillar, src_tbl, meas_name, data_dt, feature_name, grouped_columns, count_curr, prfl_run_ts, weekday)
(select 900098 as rpt_seq_num, 7851 as prfl_id, 'CUSTOM_RULES' as prfl_type, 'Consistency' as dq_pillar, 'CUST_ACCT_LINE_ADDR_V' as src_tbl,'CUST_ACCT_LINE_ADDR_V Table count' as meas_name,
cast(LAST_UPD_DT as date) as data_dt,'Tier1 Models' as feature_name, null as grouped_columns,count (*) as count_curr, current_timestamp as prfl_run_ts,
dayofweek(cast(LAST_UPD_DT as date)) as weekday from NTL_PRD_ALLVM.CUST_ACCT_LINE_ADDR_V where cast(LAST_UPD_DT as date)>= current_date -90
group by 1,2,3,4,5,6,7,8,11,12)

2025-03-20 21:57:01,335 - INFO - üìå Executing Fixed Query:
insert into "vz-it-np-izcv-dev-idmcdo-0".dga_dq_tbls.dqaas_profile_rpt
(rpt_seq_num, prfl_id, prfl_type, dq_pillar, src_tbl, meas_name, data_dt, feature_name, grouped_columns, count_curr, prfl_run_ts, weekday)
(select 900098 as rpt_seq_num, 7851 as prfl_id, 'CUSTOM_RULES' as prfl_type, 'Consistency' as dq_pillar, 'CUST_ACCT_LINE_ADDR_V' as src_tbl,'CUST_ACCT_LINE_ADDR_V Table count' as meas_name,
cast(LAST_UPD_DT as date) as data_dt,'Tier1 Models' as feature_name, null as grouped_columns,count (*) as count_curr, current_timestamp as prfl_run_ts,
dayofweek(cast(LAST_UPD_DT as date)) as weekday from NTL_PRD_ALLVM.CUST_ACCT_LINE_ADDR_V where cast(LAST_UPD_DT as date)>= current_date -90
group by 1,2,3,4,5,6,7,8,11,12)
2025-03-20 21:57:01,336 - INFO - üîÑ Connecting to Teradata...
2025-03-20 21:57:03,355 - INFO - ‚úÖ Teradata connection successful!
2025-03-20 21:57:03,356 - ERROR - ‚ùå Query execution failed: insert into "vz-it-np-izcv-dev-idmcdo-0".dga_dq_tbls.dqaas_profile_rpt
(rpt_seq_num, prfl_id, prfl_type, dq_pillar, src_tbl, meas_name, data_dt, feature_name, grouped_columns, count_curr, prfl_run_ts, weekday)
(select 900098 as rpt_seq_num, 7851 as prfl_id, 'CUSTOM_RULES' as prfl_type, 'Consistency' as dq_pillar, 'CUST_ACCT_LINE_ADDR_V' as src_tbl,'CUST_ACCT_LINE_ADDR_V Table count' as meas_name,
cast(LAST_UPD_DT as date) as data_dt,'Tier1 Models' as feature_name, null as grouped_columns,count (*) as count_curr, current_timestamp as prfl_run_ts,
dayofweek(cast(LAST_UPD_DT as date)) as weekday from NTL_PRD_ALLVM.CUST_ACCT_LINE_ADDR_V where cast(LAST_UPD_DT as date)>= current_date -90
group by 1,2,3,4,5,6,7,8,11,12)
Error: list index out of range
Internal Server Error: /mle/ExecuteHistorySQL/
2025-03-20 21:57:03,358 - ERROR - Internal Server Error: /mle/ExecuteHistorySQL/
[20/Mar/2025 21:57:03] "POST /mle/ExecuteHistorySQL/ HTTP/1.1" 500 59



{"status": "failure", "message": "list index out of range"}
