import os
import json
import logging
import pandas as pd
import time
import requests
import teradatasql
from requests.exceptions import HTTPError
from google.cloud import bigquery
import google.auth
import pandas_gbq
from django.http import JsonResponse
from django.views.decorators.csrf import csrf_exempt
from django.utils.decorators import method_decorator
from django.views import View

# ‚úÖ Teradata Configuration
dq_td_config = {
    "hostname": "TDDP.TDC.VZWCORP.COM",
    "uid": "IDQPRDLD",
    "pwd": "Newpass#969",
    "dbname": "idq_prd_tbls"
}

# ‚úÖ GCP BigQuery Configuration
dq_config = {
    "token_url": "https://ssologin.verizon.com/ngauth/oauth2/realms/root/realms/employee/access_token",
    "client_id": "27472_izcv_gcp_gz_oauth2client",
    "client_secret": "27472IZCV",
    "sa_json_file_dtls": os.path.join(os.path.dirname(__file__), "sa-pr-izcv-app-idmcdo-0-oidc-27472-config.json"),
    "conn_project_id": "vz-it-pr-izcv-idmcdo-0",
}

# ‚úÖ Initialize Logging
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)

# ‚úÖ Initialize Teradata Client
def teradata_client():
    try:
        conn = teradatasql.connect(
            host=dq_td_config["hostname"],
            user=dq_td_config["uid"],
            password=dq_td_config["pwd"],
            database=dq_td_config["dbname"]
        )
        return conn
    except Exception as err:
        logger.error(f"‚ùå Error while connecting to Teradata: {err}")
        return None

# ‚úÖ Initialize BigQuery Client
def bigquery_client():
    os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = dq_config["sa_json_file_dtls"]
    os.environ['GOOGLE_CLOUD_PROJECT'] = dq_config["conn_project_id"]
    credentials, _ = google.auth.default()
    return bigquery.Client(credentials=credentials, project=dq_config["conn_project_id"]), credentials

# ‚úÖ Load Data into BigQuery
def load_result_to_bq(dq_bq_client, dq_dest_table_name, dq_credentials, df_load_data):
    try:
        if df_load_data.empty:
            logger.warning(f"‚ö†Ô∏è No data to insert into BigQuery for table {dq_dest_table_name}")
            return

        logger.info(f"üìå DataFrame before inserting into BigQuery:\n{df_load_data}")

        pandas_gbq.to_gbq(
            dataframe=df_load_data,
            destination_table=dq_dest_table_name,
            if_exists="append",
            credentials=dq_credentials,
            project_id=dq_config["conn_project_id"],
        )
        logger.info(f"‚úÖ Successfully loaded {len(df_load_data)} rows into {dq_dest_table_name}")
    except Exception as err:
        logger.error(f"‚ùå Error loading results into BigQuery: {err}")

# ‚úÖ Process SQL File Upload and Execute Queries
@method_decorator(csrf_exempt, name="dispatch")
class ExecuteHistorySQL(View):
    def post(self, request):
        try:
            logger.info(f"üìÇ Received FILES: {request.FILES}")

            if "file" not in request.FILES:
                return JsonResponse({"status": "failure", "message": "No file uploaded."}, status=400)

            file = request.FILES["file"]
            queries = file.read().decode("utf-8").strip().split(";")
            results = {}

            for query in queries:
                query = query.strip()
                if not query:
                    continue

                logger.info(f"üìå Executing query: {query}")

                if not query.lower().startswith("select"):
                    logger.error(f"‚ö†Ô∏è Skipping non-SELECT query: {query}")
                    continue

                try:
                    conn = teradata_client()
                    if conn is None:
                        return JsonResponse({"status": "failure", "message": "Teradata connection failed."}, status=500)

                    cursor = conn.cursor()

                    # ‚úÖ Execute query
                    cursor.execute(query)
                    results_list = cursor.fetchall()

                    logger.info(f"‚úÖ Query executed successfully. Rows fetched: {len(results_list)}")

                    if not results_list:
                        logger.warning(f"‚ö†Ô∏è Query returned no data: {query}")
                        continue  # Skip processing if no results

                    df = pd.DataFrame(results_list, columns=[desc[0] for desc in cursor.description])
                    cursor.close()
                    conn.close()

                    # ‚úÖ Print DataFrame before inserting
                    logger.info(f"üìå DataFrame from Teradata:\n{df}")

                    # ‚úÖ Load results to BigQuery
                    bq_client, bq_creds = bigquery_client()
                    load_result_to_bq(
                        dq_bq_client=bq_client,
                        dq_dest_table_name="your_project.your_dataset.teradata_results",
                        dq_credentials=bq_creds,
                        df_load_data=df
                    )

                    results[query[:30]] = f"TD to GCP Query executed successfully. {len(df)} rows inserted."

                except Exception as e:
                    logger.error(f"‚ùå Query execution failed: {query}\nError: {e}")
                    return JsonResponse({"status": "failure", "message": str(e)}, status=500)

            return JsonResponse({"status": "success", "results": results}, status=200)

        except Exception as e:
            logger.error(f"‚ùå Error processing request: {e}")
            return JsonResponse({"status": "failure", "message": str(e)}, status=500)
