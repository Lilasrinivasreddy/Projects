(0:17) This should be like a dashboard, however, any example like looker dashboard or whatever (0:28) we take, it should be a kind of dashboard where we have to show the filters as well (0:36) as. (0:38) So, this testing whatever latency testing is doing, those results only we need to show (0:43) right at this. (0:45) Correct, latency testing and also accuracy testing.
(0:48) Yeah, latency and accuracy. (0:49) So, what you wish to do is latency, yeah. (0:51) So, what you wish to do is latency, but you will have accuracy testing also.
(0:55) Okay. (0:55) Right. (0:56) And based on that accuracy testing you can do this.
(0:58) Okay. (0:58) So, one thing is, one more thing, for this accuracy testing we need golden questions. (1:05) Golden questions, right.
(1:06) Yes. (1:08) So, for the golden questions what we can do is on the UI itself for any domain catalog. (1:14) Okay.
(1:14) We will give an option to upload a csv file which has the questions and SQL queries. (1:20) Okay. (1:21) Right.
(1:22) We will take that csv file, store that csv file in gcp bucket. (1:27) Okay. (1:28) Okay.
(1:28) So, we will put it in a gcp bucket and in that gcp bucket we will create a folder called (1:33) golden questions and in that golden questions we will create a domain catalog folder and (1:37) in that domain catalog we will have that particular csv file. (1:41) Okay. (1:42) And there also we can give the golden questions which are specific name . We will create folder (1:44) and add a standard format.
(1:48) We will put it on gcp bucket. (1:50) Right. (1:50) Okay.
(1:50) Now whenever someone comes to do the test they can just say run test, it will go back (1:54) in the gcp bucket, pull that file, run the accuracy test check. (1:58) Okay. (1:59) Okay.
(2:00) And one more question, here whatever yogesh script, right, there we will be getting the (2:05) complete details in a csv format. (2:07) So, there also we have the questions, right, golden questions. (2:11) So, that way we can use it? (2:13) Right.
(2:15) You can use the same data. (2:17) Okay. (2:17) Okay.
(2:19) Okay. (2:22) Understand. (2:22) Understand.
(2:23) And also, in terms of dashboard, you want me to show like anything, anything like, you (2:28) know, trend or trend, some time series analysis, those kind of charts are sufficient. (2:34) That's right. (2:35) Okay.
(2:35) Okay. (2:36) Correct. (2:36) So, on do nothing, forget about UI for now, just go and go to the backend, take the latest (2:43) backend and ask for trend or the QoS development or anything.
(2:47) Okay. (2:47) Or you can also take, okay, there's a new branch, I think it's a branch name, it already (2:52) has the GCP bucket storage port. (2:54) Okay.
(2:54) Okay. (2:55) Okay. (2:55) Okay.
(2:56) The code is already there. (2:57) So, there is a helper function where you can just call the function with the CSV file (3:01) or whatever details, right. (3:02) and it will upload the file in that particular folder structure (3:07) okay (3:08) so you can take that code, you can create your own (3:12) like you know, in the routers where we have (3:15) genie reports, you can create a new router (3:17) or a test framework or something (3:19) yeah, okay (3:20) and on the test, you can create a test framework and add your APIs to it (3:25) okay, okay, I understand (3:27) okay, okay (3:28) yeah, I mean (3:29) eventually I think we need to bring it out and operate too (3:32) but for now, I'm just thinking (3:35) or even if you think you can do it as a separate tool, that's totally fine (3:40) like if you think of creating as a separate tool, it's easier to do that (3:43) take whatever code references you need from QoS (3:46) like for the storage bucket, so you know, type of creations, not database connections (3:50) take your RFNs tool and put it in your script (3:54) okay, okay, got it, got it (3:56) sure Akhilesh, I started, I mean (3:58) I was also occupied with other work like (4:01) this morning I was in continuous calls and other tasks (4:03) so probably by this weekend, like by Friday (4:06) we will make it as a target, Akhilesh (4:09) tomorrow I have some time, so I will start completely focusing (4:12) almost 80% I can focus on this (4:15) so we can have a review tomorrow (4:18) but by Friday, I will try to finish it (4:22) yeah, yeah, try to do that (4:23) and since enough code file is not read (4:26) what you can do is (4:28) give the QoS, whatever branch I will share (4:31) just give that branch to QoS store (4:34) and tell it that, you know, use those code pieces as a reference (4:38) to create a new tool by itself (4:41) instead of putting on QoS, just ask it to create a new tool (4:44) just give it all the functionalities (4:46) so what I do is, I create a .md file (4:48) where I give, you know, phase 1, phase 2, phase 3 instructions to it (4:53) so that way it will just follow and also try that (4:56) and since you are making it as a sub-trade framework (5:00) you can also add a filter for environment (5:05) like if you want to do the testing on dev environment (5:07) you can do that, if you want to do it on PLU (5:09) you can do that, if you want to go to prod trade (5:10) just switch the APIs to prod (5:13) so you will have one framework which can connect to all the three environments (5:18) and you just switch, you give the user the option to switch (5:23) ok, ok Akhilesh, got it (5:26) sure Akhilesh, I will check that (5:31) ok, you can share those details (5:34) I will share that, yeah (5:37) sure Akhilesh, I will connect more (5:39) yeah, only thing is your GCP bucket (5:42) it might not work in dev, it might just throw you an error saying (5:45) file not saved or something (5:47) so you will have to use prod GCP account for that (5:52) ok, and I also think I won't get any kind of access to the GCS bucket (5:59) personal access, no I don't think so (6:02) yeah, I won't get it (6:03) so let me test it tomorrow so I will come to know (6:08) like whether any kind of error (6:11) on logs if it says it successfully uploaded, I think it's fine (6:15) when I come back, we can now look at it (6:19) ok, sure Akhilesh, I will connect more (6:24) ok, ok (6:26) thank you Akhilesh, bye (6:28) thanks
Ready to Go Unlimited?
Get immediate access to...

Unlimited Transcriptions
Unlimited transcriptions for one person.
üöÄ
10 Hour Uploads
Each file can be up to 10 hours long / 5 GB. Upload 50 files at a time.
Whale
All Features
Translation to 134+ languages. Bulk exports. All transcription modes. Unlimited storage.
‚ö°Ô∏è
Highest Priority
We'll always transcribe your files ASAP with the highest priority.
